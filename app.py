from asr_process import *
import gradio as gr
from pathlib import Path
import pprint

def process(audio, language="auto", model_dir='iic/SenseVoiceSmall'):
    output_folder = Path('./outputs')
    output_folder.mkdir(parents=True, exist_ok=True)
    data = transcribe(audio, output_folder, model_dir=model_dir, language=language, batch_size=10)
    pprint.pprint(data)
    return [data['words'], data['sents'], data['srt'], data['instrumental_file'], data['vacal_file'],data['clear_audio'],data['seg_times'], output_folder.absolute().as_posix(),]

# --- Gradio ç•Œé¢ ---
with gr.Blocks(theme=gr.themes.Soft()) as app:
    gr.Markdown(
        """
        # ğŸ™ï¸ éŸ³é¢‘è½¬å½•å·¥å…· (FunAsr webUI) by DataSense https://space.bilibili.com/383752637
        ä¸Šä¼ ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶æˆ–ä½¿ç”¨éº¦å…‹é£å½•éŸ³ï¼Œé€‰æ‹©è¯­è¨€å’Œæ¨¡å‹å¤§å°ï¼Œç„¶åè·å– JSON æ ¼å¼çš„è½¬å½•ç»“æœã€‚
        **æ³¨æ„:** é¦–æ¬¡é€‰æ‹©æŸä¸ªæ¨¡å‹æ—¶ï¼Œå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´æ¥ä¸‹è½½æ¨¡å‹æ–‡ä»¶ã€‚ æˆ–è€…å…ˆä¸‹è½½å…¨éƒ¨æ¨¡å‹æ–‡ä»¶: [ä¸‹è½½](https://pan.quark.cn/s/9a8b52e4cd22)ã€‚
        """
    )

    with gr.Row():
        with gr.Column(scale=1):
            audio_input = gr.Audio(
                sources=["upload", "microphone"],
                type="filepath",  # Whisper éœ€è¦æ–‡ä»¶è·¯å¾„
                label="ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶æˆ–å½•éŸ³ (Upload Audio or Record)"
            )
            model_dropdown = gr.Dropdown(
                choices=list(['iic/SenseVoiceSmall']),
                value="iic/SenseVoiceSmall", # é»˜è®¤å€¼
                label="é€‰æ‹©æ¨¡å‹ (Model)"
            )
            language_dropdown = gr.Dropdown(
                choices=list(['auto', 'en', 'zh']),
                value="auto",
                label="é€‰æ‹©è¯­è¨€ (Language)"
            )
            submit_button = gr.Button("å¼€å§‹è½¬å½• (Transcribe)", variant="primary")

        with gr.Column(scale=2):
            output_fpath = gr.Text(label="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
            instrumental_file = gr.Audio(label="èƒŒæ™¯éŸ³ä¹")
            vacal_file = gr.Audio(label="é«˜æ¸…è¯­éŸ³")
            clear_audio = gr.Audio(label="é«˜æ¸…è¯­éŸ³")
            with gr.Accordion('JSON æ•°æ®', open=False):
                seg_times = gr.JSON(label="åˆ†æ®µæ—¶é—´æˆ³", )
                word_json = gr.JSON(label="å•è¯ JSON æ ¼å¼")
                sent_json = gr.JSON(label="å¥å­ JSON æ ¼å¼")
            srt_text = gr.Textbox(label="SRT æ ¼å¼ (SubRip)")
        

    submit_button.click(
        fn=process,
        inputs=[audio_input, language_dropdown, model_dropdown],
        outputs=[word_json, sent_json, srt_text, instrumental_file, vacal_file, clear_audio, seg_times, output_fpath]
    )


if __name__ == "__main__":
    app.launch(debug=True, inbrowser=True) # debug=True å¯ä»¥åœ¨ç»ˆç«¯çœ‹åˆ°æ›´è¯¦ç»†çš„æ—¥å¿—